{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQY4EnHmFoX"
      },
      "source": [
        "## 0. Install and Import Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAHR1LMJmP-h"
      },
      "source": [
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7a3gdImMZx",
        "outputId": "59a23be5-a181-4789-e92f-defa24475895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.22.4)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (8.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=2a5a735959b1ed1a5c444b3f0a8b8c4fc0d7f2c5ffc6c6c47b9fce8c6fd6784d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=201007029374099283742884f8d86469d1265b3240302b52f894036335fd8d5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl (72.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (8.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.5.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import sys\n",
        "# import torch\n",
        "# need_pytorch3d=False\n",
        "# try:\n",
        "#     import pytorch3d\n",
        "# except ModuleNotFoundError:\n",
        "#     need_pytorch3d=True\n",
        "# if need_pytorch3d:\n",
        "#     if torch.__version__.startswith(\"1.13.\") and sys.platform.startswith(\"linux\"):\n",
        "#         # We try to install PyTorch3D via a released wheel.\n",
        "#         pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "#         version_str=\"\".join([\n",
        "#             f\"py3{sys.version_info.minor}_cu\",\n",
        "#             torch.version.cuda.replace(\".\",\"\"),\n",
        "#             f\"_pyt{pyt_version_str}\"\n",
        "#         ])\n",
        "#         !pip install fvcore iopath\n",
        "#         !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "#     else:\n",
        "#         # We try to install PyTorch3D from source.\n",
        "#         !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "#         !tar xzf 1.10.0.tar.gz\n",
        "#         os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "#         !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgLa7XQimFoY"
      },
      "outputs": [],
      "source": [
        "# # imports\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from pytorch3d.transforms.so3 import (\n",
        "#     so3_exp_map,\n",
        "#     so3_relative_angle,\n",
        "# )\n",
        "# from pytorch3d.transforms.se3 import (\n",
        "#     se3_exp_map,\n",
        "#     se3_log_map,\n",
        "# )\n",
        "\n",
        "# import pytorch3d.transforms as transforms\n",
        "    \n",
        "# # add path for demo utils\n",
        "# import sys\n",
        "# import os\n",
        "# sys.path.append(os.path.abspath(''))\n",
        "\n",
        "# # set for reproducibility\n",
        "# torch.manual_seed(42)\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda:0\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJHXNjKglfN"
      },
      "source": [
        "## **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_-eCm8alLqz"
      },
      "outputs": [],
      "source": [
        "# # Load the matrices \n",
        "# T_o_cb_batch = np.load('')\n",
        "# batch_size = T_o_cb_batch.shape[0]\n",
        "# T_o_p_batch = np.load('')\n",
        "# T_c_p_batch = np.load('')\n",
        "# X_matrix = np.load('')\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "\n",
        "# # Load into torch tensor\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbh1fFj-yOs4",
        "outputId": "ba72a33c-5d29-429e-c6b7-8b69fb57a246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.49508795 -0.8619929  -0.10888599  2.        ]\n",
            " [-0.86414445  0.47551297  0.16474763  2.        ]\n",
            " [-0.09023459  0.17565779 -0.98030712  2.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# ## test\n",
        "# from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# batch_size = 10\n",
        "# T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "# X_batch[:, :3, 3] = 2\n",
        "# print(X_batch[1, :,:])\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vy3GDAbgpxj"
      },
      "outputs": [],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # cam_gt: the ground truth camera pose w.r.t the optical tracker cam_gt = T_o_p * (T_c_p)^-1\n",
        "# cam_gt = T_o_cb.compose(X)\n",
        "\n",
        "# # cam_real: the camera pose from initial hand-eye calibration cam_real = T_o_cb * X\n",
        "# cam_real = T_o_p.compose(T_c_p.inverse())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om0hsJi5S6Pl"
      },
      "source": [
        "## **Define optimization loss function**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDA0vbgRSsD8"
      },
      "outputs": [],
      "source": [
        "# def camera_distance(hand_eye_real, hand_eye_gt):\n",
        "#   '''\n",
        "#   Calculate the l2 distance in se(3) manifold for the camera.\n",
        "#   distance = sum||log(hand_eye_real*hand_eye_gt)||_2\n",
        "#   '''\n",
        "\n",
        "#   # Convert a batch of 4x4 transformation matrices transform to \n",
        "#   # a batch of 6-dimensional SE(3) logarithms of the SE(3) matrices\n",
        "#   # print(hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix())\n",
        "#   tmp_matrix = hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix()\n",
        "#   vec = se3_log_map(tmp_matrix.permute(0,2,1)).sum(0)\n",
        "#   # print(torch.norm(vec))\n",
        "\n",
        "#   return torch.norm(vec)\n",
        "  \n",
        "\n",
        "# # camera_distance(cam_real, cam_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHQaC9QHs5K5"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STvOIf2IxfG6",
        "outputId": "0a326309-aa65-40f3-8168-a2e9df4c1655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration=  0; camera_distance=4.696e+01\n",
            "iteration=200; camera_distance=2.786e+01\n",
            "iteration=400; camera_distance=7.859e+00\n",
            "iteration=600; camera_distance=5.260e-04\n",
            "iteration=800; camera_distance=1.630e-02\n",
            "iteration=1000; camera_distance=7.543e-03\n",
            "iteration=1200; camera_distance=1.241e-02\n",
            "iteration=1400; camera_distance=7.818e-03\n",
            "iteration=1600; camera_distance=1.311e-02\n",
            "iteration=1800; camera_distance=3.938e-03\n",
            "iteration=1999; camera_distance=4.000e-03\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "# hand_eye_real_6D = se3_log_map(X.get_matrix().permute(0, 2, 1))\n",
        "# hand_eye_real_6D.requires_grad = True\n",
        "\n",
        "\n",
        "# # hand_eye_gt: the hand-eye transformation from the chain \n",
        "# # hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "# hand_eye_gt = T_o_cb.inverse().compose(T_o_p).compose(T_c_p.inverse())\n",
        "\n",
        "# # init the optimizer\n",
        "# optimizer = torch.optim.SGD([hand_eye_real_6D], lr=.001, momentum=0.9)\n",
        "\n",
        "# # run the optimization\n",
        "# n_iter = 2000  # fix the number of iterations\n",
        "# for it in range(n_iter):\n",
        "#     # re-init the optimizer gradients\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # transform the 6d vector into 4x4 matrix\n",
        "#     hand_eye_real = se3_exp_map(hand_eye_real_6D).permute(0, 2, 1)\n",
        "#     hand_eye_real = transforms.Transform3d(matrix=hand_eye_real, device=device)\n",
        "\n",
        "#     # compare the composed cameras with the ground truth relative cameras\n",
        "#     # camera_distance corresponds to $d$ from the description\n",
        "#     loss = \\\n",
        "#         camera_distance(hand_eye_real, hand_eye_gt)\n",
        "#     # loss.requires_grad_(True)\n",
        "\n",
        "#     # our loss function is the camera_distance\n",
        "#     loss.backward()\n",
        "    \n",
        "#     # apply the gradients\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # # plot and print status message\n",
        "#     if it % 200==0 or it==n_iter-1:\n",
        "#         status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "#         print(status)\n",
        "        \n",
        "# print('Optimization finished.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0Yz1ZM_bVG"
      },
      "source": [
        "## **Pypose implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHwar1t7_vlQ",
        "outputId": "94728a50-1b0a-4b15-d4f4-b95fb82b0e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypose\n",
            "  Downloading pypose-0.3.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.* in /usr/local/lib/python3.8/dist-packages (from pypose) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pypose) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.*->pypose) (4.5.0)\n",
            "Installing collected packages: pypose\n",
            "Successfully installed pypose-0.3.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install pypose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XHwVk3I7AJWz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch, pypose as pp\n",
        "from torch import nn\n",
        "from scipy.spatial.transform import Rotation as R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "efn4AgnkTlB3"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSkG7iFI2TAE"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "T_c_p_batch = np.load(os.path.join(params_save_dir, 'T_c_p_opti3.npy'))\n",
        "T_c_p_batch_zed = np.load(os.path.join(params_save_dir, 'T_c_p_opti3zed.npy'))\n",
        "\n",
        "T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "T_c_p_zed = pp.mat2SE3(T_c_p_batch_zed)\n",
        "# T_c_p @ pp.Inv(T_c_p_zed)\n",
        "print([T_c_p[i][:3].norm().item() for i in range(160)],'\\n',[T_c_p_zed[i][:3].norm().item() for i in range(41)])\n",
        "# print(T_c_p_batch[0],'\\n',T_c_p_batch_zed[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "PoZzXm_s2Hhi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1243, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# # Load the matrices\n",
        "params_save_dir = '../data/post_optimization_data/'\n",
        "T_o_cb_batch = np.load(os.path.join(params_save_dir, 'T_o_cb_opti3.npy'))[:150]\n",
        "T_o_cb_batch[:,:3, 3] /= 1000 \n",
        "batch_size = T_o_cb_batch.shape[0]\n",
        "T_o_p_batch = np.load(os.path.join(params_save_dir, 'T_o_p_opti3.npy'))[:150]\n",
        "T_o_p_batch[:,:3, 3] /= 1000\n",
        "T_c_p_batch = np.load(os.path.join(params_save_dir, 'T_c_p_opti3zed.npy'))[:150]\n",
        "T_c_p_batch[:,:3, 3] /= 1000\n",
        "X_matrix = np.load('../params/hand_eye_X_0220.npy')\n",
        "X_matrix[:3, 3] /= 1000\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])[:40]\n",
        "\n",
        "# convert to pp tensor\n",
        "X = pp.mat2SE3(X_matrix)\n",
        "T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "\n",
        "# print(np.linalg.norm(X_batch[1, :3,3]))\n",
        "print(X[:3].norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33skIGPvAgcG",
        "outputId": "549c1692-ecde-4aee-bea1-5dcefe9b6b53"
      },
      "outputs": [],
      "source": [
        "# # test\n",
        "# batch_size = 800\n",
        "# T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "# X_batch[:, :3, 3] = 2.5\n",
        "\n",
        "# print(X_batch[1, :,:])\n",
        "\n",
        "# # convert to pp tensor\n",
        "# X = pp.mat2SE3(X_batch)\n",
        "# T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "# T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "# T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "# # print(X_batch[1,...])\n",
        "# # print(X_batch @ pp.Inv(X_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3m2c_51-ON"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "9GqcVTBSY-Sy"
      },
      "outputs": [],
      "source": [
        "class CamDis(nn.Module):\n",
        "    def __init__(self, hand_eye_real_6D):\n",
        "        super().__init__()\n",
        "        self.real = pp.Parameter(hand_eye_real_6D)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input hand_eye_gt\n",
        "        hand_eye_real = self.real.Exp()\n",
        "        tmp_quats = pp.Inv(hand_eye_real) @ input\n",
        "        vec = tmp_quats.Log()\n",
        "        t = tmp_quats[:, :3].mean(0)\n",
        "        rot_vec = vec[:, 3:].mean(0)\n",
        "        # print(self.real.Exp())\n",
        "        return t.norm() + rot_vec.norm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([150, 7])\n",
            "tensor(0.1243, dtype=torch.float64)\n",
            "[0.12938696244371226, 0.13031321266780965, 0.13122056046503783, 0.13074747792270724, 0.13093554471659627, 0.1312828602486734, 0.13171319895265735, 0.13263997988197918, 0.1340988850882946, 0.132123919294936, 0.13232468656155988, 0.13100444750158227, 0.13147318927977159, 0.1317402825657335, 0.13103063831723974, 0.1310387568863373, 0.13298470118556988, 0.1350633595663893, 0.1422564702940825, 0.14432143905572603, 0.12745192506317815, 0.1283203116317409, 0.12929842102438305, 0.13152221597077932, 0.12657259807956583, 0.1297832769391131, 0.1337537602883679, 0.13298695228159113, 0.13369253823686397, 0.12979472946272366, 0.13103521025844286, 0.13019661757430978, 0.13079871061901846, 0.13030468638285467, 0.13056573388299272, 0.12927139947572194, 0.12959650309009238, 0.12809534649169174, 0.12690133237520276, 0.12812610845788866]\n",
            "SE3Type LieTensor:\n",
            "LieTensor([[ 6.2738e-03,  3.4432e-04,  7.4286e-03,  ..., -8.7473e-03,\n",
            "             3.2501e-03,  1.2160e-02],\n",
            "           [ 3.7268e-03, -3.9049e-05,  7.8145e-03,  ..., -9.3247e-03,\n",
            "            -5.7763e-04,  1.3222e-02],\n",
            "           [-4.1266e-04,  1.8607e-04,  7.4351e-03,  ..., -3.6797e-03,\n",
            "            -7.7876e-03,  1.2744e-02],\n",
            "           ...,\n",
            "           [ 6.3517e-03, -2.6017e-03,  1.5348e-02,  ..., -6.2069e-02,\n",
            "             1.5880e-02,  8.6312e-03],\n",
            "           [ 1.0596e-02, -6.4872e-03,  1.6656e-02,  ..., -4.7592e-02,\n",
            "             2.0337e-02,  1.8667e-02],\n",
            "           [ 9.7430e-03, -4.0780e-03,  1.4827e-02,  ..., -4.6721e-02,\n",
            "             1.6621e-02,  1.5270e-02]], dtype=torch.float64)\n",
            "tensor([0.0023, 0.0076, 0.0083], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "hand_eye_gt = pp.Inv(T_o_cb) @ T_o_p @ pp.Inv(T_c_p)\n",
        "hand_eye_gt = hand_eye_gt.to('cpu')\n",
        "hand_eye_real = X\n",
        "# hand_eye_gt[:3] = hand_eye_gt[:3]/1000\n",
        "print(hand_eye_gt.shape)\n",
        "print(X[:3].norm())\n",
        "print([hand_eye_gt[i,:3].norm().item() for i in range(40)])\n",
        "print(pp.Inv(hand_eye_real)*hand_eye_gt)\n",
        "# print(hand_eye_real*pp.Inv(hand_eye_gt))\n",
        "test = pp.Inv(hand_eye_real)*hand_eye_gt\n",
        "print(test[:, :3].mean(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJomeMEsVpw5",
        "outputId": "27b5ee7c-9336-48fa-ef72-316e35185c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SE3Type LieTensor:\n",
            "LieTensor([ 0.0202,  0.0986,  0.0730, -0.2865,  0.5003,  0.3674,  0.7298],\n",
            "          device='cuda:0', dtype=torch.float64)\n",
            "iteration=  0; camera_distance=6.520e+00\n",
            "iteration=100; camera_distance=6.504e+00\n",
            "iteration=200; camera_distance=6.501e+00\n",
            "iteration=300; camera_distance=6.498e+00\n",
            "iteration=400; camera_distance=6.495e+00\n",
            "iteration=500; camera_distance=6.492e+00\n",
            "iteration=600; camera_distance=6.490e+00\n",
            "iteration=700; camera_distance=6.487e+00\n",
            "iteration=800; camera_distance=6.484e+00\n",
            "iteration=900; camera_distance=6.481e+00\n",
            "iteration=1000; camera_distance=6.478e+00\n",
            "iteration=1100; camera_distance=6.475e+00\n",
            "iteration=1200; camera_distance=6.473e+00\n",
            "iteration=1300; camera_distance=6.473e+00\n",
            "iteration=1400; camera_distance=6.473e+00\n",
            "iteration=1500; camera_distance=6.473e+00\n",
            "iteration=1600; camera_distance=6.473e+00\n",
            "iteration=1700; camera_distance=6.473e+00\n",
            "iteration=1800; camera_distance=6.473e+00\n",
            "iteration=1900; camera_distance=6.473e+00\n",
            "iteration=1999; camera_distance=6.473e+00\n",
            "The final result:\n",
            " SE3Type LieTensor:\n",
            "LieTensor([ 0.1747,  0.1768,  0.0062, -0.2676,  0.5513,  0.3418,  0.7125],\n",
            "          device='cuda:0', dtype=torch.float64, grad_fn=<AliasBackward0>)\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "\n",
        "hand_eye_real = X.clone().detach()\n",
        "hand_eye_real_6D = hand_eye_real.Log()\n",
        "print(hand_eye_real)\n",
        "# hand_eye_gt: the hand-eye transformation from the chain \n",
        "# hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "hand_eye_gt = pp.Inv(T_o_cb) @ T_o_p @ pp.Inv(T_c_p)\n",
        "hand_eye_gt = hand_eye_gt.clone().detach()\n",
        "# print(np.linalg.norm(hand_eye_gt[4].matrix()[:3,3]))\n",
        "# print(np.linalg.norm(X[0].matrix()[:3,3]))\n",
        "\n",
        "# init the optimizer\n",
        "camera_distance = CamDis(hand_eye_real_6D).to(device)\n",
        "input = hand_eye_gt.to(device)\n",
        "strategy = pp.optim.strategy.Adaptive(damping=2e-6)\n",
        "optimizer = pp.optim.LM(camera_distance, strategy=strategy)\n",
        "# run the optimization\n",
        "n_iter = 2000  # fix the number of iterations\n",
        "for it in range(n_iter):\n",
        "    loss = optimizer.step(input)\n",
        "    # # plot and print status message\n",
        "    if it % 100==0 or it==n_iter-1:\n",
        "        status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "        print(status)\n",
        "        # print(camera_distance.real.Exp())\n",
        "    if loss < 1e-4:\n",
        "        print('Early Stopping with loss:', loss.item())\n",
        "        break\n",
        "res = camera_distance.real.Exp()\n",
        "print('The final result:\\n', res)\n",
        "print('Optimization finished.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SE3Type LieTensor:\n",
            "LieTensor([ 0.0202,  0.0986,  0.0730, -0.2865,  0.5003,  0.3674,  0.7298],\n",
            "          device='cuda:0', dtype=torch.float64)\n",
            "SE3Type LieTensor:\n",
            "LieTensor([ 0.1747,  0.1768,  0.0062, -0.2676,  0.5513,  0.3418,  0.7125],\n",
            "          device='cuda:0', dtype=torch.float64, grad_fn=<AliasBackward0>)\n",
            "tensor(0.1243, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.2486, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)\n"
          ]
        }
      ],
      "source": [
        "X = X.to(device)\n",
        "# print(input[0,:3].norm())\n",
        "print(X)\n",
        "print(res)\n",
        "print(X[:3].norm())\n",
        "print(res[:3].norm())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SE3Type LieTensor:\n",
            "LieTensor([ 13.8470, 109.8871,  76.9371,  -0.7170,  -0.3874,   0.5053,  -0.2838],\n",
            "          device='cuda:0', dtype=torch.float64) SE3Type LieTensor:\n",
            "LieTensor([20.2430, 98.5587, 72.9542, -0.2865,  0.5003,  0.3674,  0.7298],\n",
            "          device='cuda:0', dtype=torch.float64)\n",
            "tensor([[ 2.2935e-01, -8.2292e-01,  5.1981e-01,  2.0243e+01],\n",
            "        [ 2.4962e-01,  5.6591e-01,  7.8577e-01,  9.8559e+01],\n",
            "        [-9.4079e-01, -5.0468e-02,  3.3521e-01,  7.2954e+01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0',\n",
            "       dtype=torch.float64) \n",
            " tensor([[ 9.9900e-01,  4.4030e-02, -7.1768e-03,  1.9283e+00],\n",
            "        [ 4.4164e-02, -9.9883e-01,  1.9741e-02,  1.1429e+01],\n",
            "        [-6.2993e-03, -2.0038e-02, -9.9978e-01,  7.1253e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(pp.matrix(X),'\\n', pp.matrix(pp.Inv(res))@ pp.matrix(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.29353474e-01, -8.22919865e-01,  5.19807541e-01,\n",
              "         2.02430249e+01],\n",
              "       [ 2.49615163e-01,  5.65911589e-01,  7.85771178e-01,\n",
              "         9.85586502e+01],\n",
              "       [-9.40791823e-01, -5.04675049e-02,  3.35207065e-01,\n",
              "         7.29542443e+01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         1.00000000e+00]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "handeyeX = np.load('hand_eye_X.npy')\n",
        "handeyeX"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nAQY4EnHmFoX",
        "om0hsJi5S6Pl",
        "rHQaC9QHs5K5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch3d",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ce49f5ef5efef132947d6c894613f203ae812a6bb9ec04c63c99638f20d472f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
