{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQY4EnHmFoX"
      },
      "source": [
        "## 0. Install and Import Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAHR1LMJmP-h"
      },
      "source": [
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7a3gdImMZx",
        "outputId": "59a23be5-a181-4789-e92f-defa24475895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.22.4)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (8.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=2a5a735959b1ed1a5c444b3f0a8b8c4fc0d7f2c5ffc6c6c47b9fce8c6fd6784d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=201007029374099283742884f8d86469d1265b3240302b52f894036335fd8d5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl (72.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (8.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.5.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import sys\n",
        "# import torch\n",
        "# need_pytorch3d=False\n",
        "# try:\n",
        "#     import pytorch3d\n",
        "# except ModuleNotFoundError:\n",
        "#     need_pytorch3d=True\n",
        "# if need_pytorch3d:\n",
        "#     if torch.__version__.startswith(\"1.13.\") and sys.platform.startswith(\"linux\"):\n",
        "#         # We try to install PyTorch3D via a released wheel.\n",
        "#         pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "#         version_str=\"\".join([\n",
        "#             f\"py3{sys.version_info.minor}_cu\",\n",
        "#             torch.version.cuda.replace(\".\",\"\"),\n",
        "#             f\"_pyt{pyt_version_str}\"\n",
        "#         ])\n",
        "#         !pip install fvcore iopath\n",
        "#         !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "#     else:\n",
        "#         # We try to install PyTorch3D from source.\n",
        "#         !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "#         !tar xzf 1.10.0.tar.gz\n",
        "#         os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "#         !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgLa7XQimFoY"
      },
      "outputs": [],
      "source": [
        "# # imports\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from pytorch3d.transforms.so3 import (\n",
        "#     so3_exp_map,\n",
        "#     so3_relative_angle,\n",
        "# )\n",
        "# from pytorch3d.transforms.se3 import (\n",
        "#     se3_exp_map,\n",
        "#     se3_log_map,\n",
        "# )\n",
        "\n",
        "# import pytorch3d.transforms as transforms\n",
        "    \n",
        "# # add path for demo utils\n",
        "# import sys\n",
        "# import os\n",
        "# sys.path.append(os.path.abspath(''))\n",
        "\n",
        "# # set for reproducibility\n",
        "# torch.manual_seed(42)\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda:0\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJHXNjKglfN"
      },
      "source": [
        "## **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_-eCm8alLqz"
      },
      "outputs": [],
      "source": [
        "# # Load the matrices \n",
        "# T_o_cb_batch = np.load('')\n",
        "# batch_size = T_o_cb_batch.shape[0]\n",
        "# T_o_p_batch = np.load('')\n",
        "# T_c_p_batch = np.load('')\n",
        "# X_matrix = np.load('')\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "\n",
        "# # Load into torch tensor\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbh1fFj-yOs4",
        "outputId": "ba72a33c-5d29-429e-c6b7-8b69fb57a246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.49508795 -0.8619929  -0.10888599  2.        ]\n",
            " [-0.86414445  0.47551297  0.16474763  2.        ]\n",
            " [-0.09023459  0.17565779 -0.98030712  2.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# ## test\n",
        "# from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# batch_size = 10\n",
        "# T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "# X_batch[:, :3, 3] = 2\n",
        "# print(X_batch[1, :,:])\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vy3GDAbgpxj"
      },
      "outputs": [],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # cam_gt: the ground truth camera pose w.r.t the optical tracker cam_gt = T_o_p * (T_c_p)^-1\n",
        "# cam_gt = T_o_cb.compose(X)\n",
        "\n",
        "# # cam_real: the camera pose from initial hand-eye calibration cam_real = T_o_cb * X\n",
        "# cam_real = T_o_p.compose(T_c_p.inverse())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om0hsJi5S6Pl"
      },
      "source": [
        "## **Define optimization loss function**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDA0vbgRSsD8"
      },
      "outputs": [],
      "source": [
        "# def camera_distance(hand_eye_real, hand_eye_gt):\n",
        "#   '''\n",
        "#   Calculate the l2 distance in se(3) manifold for the camera.\n",
        "#   distance = sum||log(hand_eye_real*hand_eye_gt)||_2\n",
        "#   '''\n",
        "\n",
        "#   # Convert a batch of 4x4 transformation matrices transform to \n",
        "#   # a batch of 6-dimensional SE(3) logarithms of the SE(3) matrices\n",
        "#   # print(hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix())\n",
        "#   tmp_matrix = hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix()\n",
        "#   vec = se3_log_map(tmp_matrix.permute(0,2,1)).sum(0)\n",
        "#   # print(torch.norm(vec))\n",
        "\n",
        "#   return torch.norm(vec)\n",
        "  \n",
        "\n",
        "# # camera_distance(cam_real, cam_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHQaC9QHs5K5"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STvOIf2IxfG6",
        "outputId": "0a326309-aa65-40f3-8168-a2e9df4c1655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration=  0; camera_distance=4.696e+01\n",
            "iteration=200; camera_distance=2.786e+01\n",
            "iteration=400; camera_distance=7.859e+00\n",
            "iteration=600; camera_distance=5.260e-04\n",
            "iteration=800; camera_distance=1.630e-02\n",
            "iteration=1000; camera_distance=7.543e-03\n",
            "iteration=1200; camera_distance=1.241e-02\n",
            "iteration=1400; camera_distance=7.818e-03\n",
            "iteration=1600; camera_distance=1.311e-02\n",
            "iteration=1800; camera_distance=3.938e-03\n",
            "iteration=1999; camera_distance=4.000e-03\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "# hand_eye_real_6D = se3_log_map(X.get_matrix().permute(0, 2, 1))\n",
        "# hand_eye_real_6D.requires_grad = True\n",
        "\n",
        "\n",
        "# # hand_eye_gt: the hand-eye transformation from the chain \n",
        "# # hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "# hand_eye_gt = T_o_cb.inverse().compose(T_o_p).compose(T_c_p.inverse())\n",
        "\n",
        "# # init the optimizer\n",
        "# optimizer = torch.optim.SGD([hand_eye_real_6D], lr=.001, momentum=0.9)\n",
        "\n",
        "# # run the optimization\n",
        "# n_iter = 2000  # fix the number of iterations\n",
        "# for it in range(n_iter):\n",
        "#     # re-init the optimizer gradients\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # transform the 6d vector into 4x4 matrix\n",
        "#     hand_eye_real = se3_exp_map(hand_eye_real_6D).permute(0, 2, 1)\n",
        "#     hand_eye_real = transforms.Transform3d(matrix=hand_eye_real, device=device)\n",
        "\n",
        "#     # compare the composed cameras with the ground truth relative cameras\n",
        "#     # camera_distance corresponds to $d$ from the description\n",
        "#     loss = \\\n",
        "#         camera_distance(hand_eye_real, hand_eye_gt)\n",
        "#     # loss.requires_grad_(True)\n",
        "\n",
        "#     # our loss function is the camera_distance\n",
        "#     loss.backward()\n",
        "    \n",
        "#     # apply the gradients\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # # plot and print status message\n",
        "#     if it % 200==0 or it==n_iter-1:\n",
        "#         status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "#         print(status)\n",
        "        \n",
        "# print('Optimization finished.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0Yz1ZM_bVG"
      },
      "source": [
        "## **Pypose implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHwar1t7_vlQ",
        "outputId": "94728a50-1b0a-4b15-d4f4-b95fb82b0e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypose\n",
            "  Downloading pypose-0.3.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.* in /usr/local/lib/python3.8/dist-packages (from pypose) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pypose) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.*->pypose) (4.5.0)\n",
            "Installing collected packages: pypose\n",
            "Successfully installed pypose-0.3.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install pypose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XHwVk3I7AJWz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch, pypose as pp\n",
        "from torch import nn\n",
        "from scipy.spatial.transform import Rotation as R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "efn4AgnkTlB3"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSkG7iFI2TAE"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T_c_p_batch = np.load(os.path.join(params_save_dir, 'T_c_p_opti3.npy'))\n",
        "# T_c_p_batch_zed = np.load(os.path.join(params_save_dir, 'T_c_p_opti3zed.npy'))\n",
        "\n",
        "# T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "# T_c_p_zed = pp.mat2SE3(T_c_p_batch_zed)\n",
        "# # T_c_p @ pp.Inv(T_c_p_zed)\n",
        "# print([T_c_p[i][:3].norm().item() for i in range(160)],'\\n',[T_c_p_zed[i][:3].norm().item() for i in range(41)])\n",
        "# # print(T_c_p_batch[0],'\\n',T_c_p_batch_zed[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "PoZzXm_s2Hhi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1243, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# # Load the matrices\n",
        "params_save_dir = '../data/post_optimization_data/'\n",
        "T_o_cb_batch = np.load(os.path.join(params_save_dir, 'T_o_cb_opti3.npy'))[:150]\n",
        "T_o_cb_batch[:,:3, 3] /= 1000 \n",
        "batch_size = T_o_cb_batch.shape[0]\n",
        "T_o_p_batch = np.load(os.path.join(params_save_dir, 'T_o_p_opti3.npy'))[:150]\n",
        "T_o_p_batch[:,:3, 3] /= 1000\n",
        "T_c_p_batch = np.load(os.path.join(params_save_dir, 'T_c_p_opti3zed.npy'))[:150]\n",
        "T_c_p_batch[:,:3, 3] /= 1000\n",
        "X_matrix = np.load('../params/hand_eye_X_0220.npy')\n",
        "X_matrix[:3, 3] /= 1000\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])[:40]\n",
        "\n",
        "# convert to pp tensor\n",
        "X = pp.mat2SE3(X_matrix)\n",
        "T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "\n",
        "# print(np.linalg.norm(X_batch[1, :3,3]))\n",
        "print(X[:3].norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33skIGPvAgcG",
        "outputId": "549c1692-ecde-4aee-bea1-5dcefe9b6b53"
      },
      "outputs": [],
      "source": [
        "# # test\n",
        "# batch_size = 800\n",
        "# T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "# X_batch[:, :3, 3] = 2.5\n",
        "\n",
        "# print(X_batch[1, :,:])\n",
        "\n",
        "# # convert to pp tensor\n",
        "# X = pp.mat2SE3(X_batch)\n",
        "# T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "# T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "# T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "# # print(X_batch[1,...])\n",
        "# # print(X_batch @ pp.Inv(X_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3m2c_51-ON"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "9GqcVTBSY-Sy"
      },
      "outputs": [],
      "source": [
        "class CamDis(nn.Module):\n",
        "    def __init__(self, hand_eye_real_6D):\n",
        "        super().__init__()\n",
        "        self.real = pp.Parameter(hand_eye_real_6D)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input hand_eye_gt\n",
        "        hand_eye_real = self.real.Exp()\n",
        "        tmp_quats = pp.Inv(hand_eye_real) @ input\n",
        "        vec = tmp_quats.Log()\n",
        "        t = tmp_quats[:, :3].mean(0)\n",
        "        rot_vec = vec[:, 3:].mean(0)\n",
        "        return t.norm() + rot_vec.norm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([150, 7])\n",
            "tensor(0.1243, dtype=torch.float64)\n",
            "[0.12938696244371226, 0.13031321266780965, 0.13122056046503783, 0.13074747792270724, 0.13093554471659627, 0.1312828602486734, 0.13171319895265735, 0.13263997988197918, 0.1340988850882946, 0.132123919294936, 0.13232468656155988, 0.13100444750158227, 0.13147318927977159, 0.1317402825657335, 0.13103063831723974, 0.1310387568863373, 0.13298470118556988, 0.1350633595663893, 0.1422564702940825, 0.14432143905572603, 0.12745192506317815, 0.1283203116317409, 0.12929842102438305, 0.13152221597077932, 0.12657259807956583, 0.1297832769391131, 0.1337537602883679, 0.13298695228159113, 0.13369253823686397, 0.12979472946272366, 0.13103521025844286, 0.13019661757430978, 0.13079871061901846, 0.13030468638285467, 0.13056573388299272, 0.12927139947572194, 0.12959650309009238, 0.12809534649169174, 0.12690133237520276, 0.12812610845788866, 0.12698242232724657, 0.1269299298141815, 0.1267837093741542, 0.1271693625902082, 0.1319050135712366, 0.12785451072072285, 0.12823694682217707, 0.1299034862264066, 0.1298605779666207, 0.1293399431210467, 0.12757265856174616, 0.12923810244534917, 0.12723178474094607, 0.1260547486424228, 0.1252492317223206, 0.14962202475344122, 0.15279743604575924, 0.1495424049130704, 0.14981232977211462, 0.14811048906295568, 0.15132410772970334, 0.15435234147318733, 0.15520306416182456, 0.15555191538221685, 0.15816659663026938, 0.15955013674625937, 0.15843878694194052, 0.14537118128207632, 0.14496880882756522, 0.1413037190014459, 0.14068498618708686, 0.14112299408615755, 0.14120291044066158, 0.13918288956373337, 0.13869240082762446, 0.13793864036472145, 0.13790109100558637, 0.1383543738884823, 0.138849700189575, 0.13972517098918152, 0.13815703501023927, 0.13815139457074796, 0.1382180107851733, 0.13773013426641018, 0.13721779060258582, 0.13788239318464335, 0.1381315576566043, 0.13812668729869162, 0.13755309534025323, 0.13639723409064172, 0.13621606447427442, 0.12727330492683867, 0.12849047489817683, 0.12861190696151256, 0.12823647913285055, 0.12793471315023205, 0.12724325758432808, 0.126651826541758, 0.12709171425321625, 0.12788781314557565, 0.12840472262735872, 0.12781994504070626, 0.12784888210224196, 0.12753935641566005, 0.12676619280893017, 0.12584880652454009, 0.1252557632255451, 0.12433340726175543, 0.1253087776043813, 0.12593600092498533, 0.12814001865482005, 0.12893244920647307, 0.12850778056343076, 0.12914838334175677, 0.12818234808483553, 0.12876644482196695, 0.13143252367772335, 0.1321178207800652, 0.13223690226949653, 0.13083786213044968, 0.1302034915504354, 0.13106198906897287, 0.12935958977172182, 0.12662641273642042, 0.13563256899342316, 0.13533916891038303, 0.13603158337213533, 0.13587488925349664, 0.1368623651033929, 0.16235327771886998, 0.1385105611368252, 0.13632448231349098, 0.13377581074155326, 0.13331012685674673, 0.1335793984912481, 0.13501903852688046, 0.13265206426680234, 0.13483173803542053, 0.1338454040540923, 0.13658778866640944, 0.13410807629795715, 0.13461354982623985, 0.13535325643175186, 0.1360598061472652, 0.1361636392781356, 0.1368869962252225, 0.13739181124933506, 0.13599517985676543, 0.1353817895672187, 0.1343669902333028]\n",
            "tensor(0.0115, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# hand_eye_gt = pp.Inv(T_o_cb) @ T_o_p @ pp.Inv(T_c_p)\n",
        "# hand_eye_gt = hand_eye_gt.to('cpu')\n",
        "# hand_eye_real = X\n",
        "# # hand_eye_gt[:3] = hand_eye_gt[:3]/1000\n",
        "# print(hand_eye_gt.shape)\n",
        "# print(X[:3].norm())\n",
        "# print([hand_eye_gt[i,:3].norm().item() for i in range(150)])\n",
        "# # print(hand_eye_real*pp.Inv(hand_eye_gt))\n",
        "# test = pp.Inv(hand_eye_real)*hand_eye_gt\n",
        "# print(test[:, :3].mean(0).norm())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJomeMEsVpw5",
        "outputId": "27b5ee7c-9336-48fa-ef72-316e35185c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SE3Type LieTensor:\n",
            "LieTensor([ 0.0202,  0.0986,  0.0730, -0.2865,  0.5003,  0.3674,  0.7298],\n",
            "          dtype=torch.float64)\n",
            "iteration=  0; camera_distance=6.520e+00\n",
            "iteration=100; camera_distance=6.504e+00\n",
            "iteration=200; camera_distance=6.501e+00\n",
            "iteration=300; camera_distance=6.498e+00\n",
            "iteration=400; camera_distance=6.495e+00\n",
            "iteration=500; camera_distance=6.492e+00\n",
            "iteration=600; camera_distance=6.490e+00\n",
            "iteration=700; camera_distance=6.487e+00\n",
            "iteration=800; camera_distance=6.484e+00\n",
            "iteration=900; camera_distance=6.481e+00\n",
            "iteration=1000; camera_distance=6.478e+00\n",
            "iteration=1100; camera_distance=6.475e+00\n",
            "iteration=1200; camera_distance=6.473e+00\n",
            "iteration=1300; camera_distance=6.473e+00\n",
            "iteration=1400; camera_distance=6.473e+00\n",
            "iteration=1500; camera_distance=6.473e+00\n",
            "iteration=1600; camera_distance=6.473e+00\n",
            "iteration=1700; camera_distance=6.473e+00\n",
            "iteration=1800; camera_distance=6.473e+00\n",
            "iteration=1900; camera_distance=6.473e+00\n",
            "iteration=1999; camera_distance=6.473e+00\n",
            "The final result:\n",
            " SE3Type LieTensor:\n",
            "LieTensor([ 0.1750,  0.1761,  0.0063, -0.2676,  0.5513,  0.3418,  0.7125],\n",
            "          device='cuda:0', dtype=torch.float64, grad_fn=<AliasBackward0>)\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "\n",
        "hand_eye_real = X.clone().detach()\n",
        "hand_eye_real_6D = hand_eye_real.Log()\n",
        "print(hand_eye_real)\n",
        "# hand_eye_gt: the hand-eye transformation from the chain \n",
        "# hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "hand_eye_gt = pp.Inv(T_o_cb) @ T_o_p @ pp.Inv(T_c_p)\n",
        "hand_eye_gt = hand_eye_gt.clone().detach()\n",
        "# print(np.linalg.norm(hand_eye_gt[4].matrix()[:3,3]))\n",
        "# print(np.linalg.norm(X[0].matrix()[:3,3]))\n",
        "\n",
        "# init the optimizer\n",
        "camera_distance = CamDis(hand_eye_real_6D).to(device)\n",
        "input = hand_eye_gt.to(device)\n",
        "strategy = pp.optim.strategy.Adaptive(damping=2e-6)\n",
        "optimizer = pp.optim.LM(camera_distance, strategy=strategy)\n",
        "# run the optimization\n",
        "n_iter = 2000  # fix the number of iterations\n",
        "for it in range(n_iter):\n",
        "    loss = optimizer.step(input)\n",
        "    # # plot and print status message\n",
        "    if it % 100==0 or it==n_iter-1:\n",
        "        status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "        print(status)\n",
        "        # print(camera_distance.real.Exp())\n",
        "    if loss < 1e-4:\n",
        "        print('Early Stopping with loss:', loss.item())\n",
        "        break\n",
        "res = camera_distance.real.Exp()\n",
        "print('The final result:\\n', res)\n",
        "print('Optimization finished.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial X:\n",
            " SE3Type LieTensor:\n",
            "LieTensor([ 0.0202,  0.0986,  0.0730, -0.2865,  0.5003,  0.3674,  0.7298],\n",
            "          device='cuda:0', dtype=torch.float64)\n",
            "optimization result:\n",
            " SE3Type LieTensor:\n",
            "LieTensor([ 0.1750,  0.1761,  0.0063, -0.2676,  0.5513,  0.3418,  0.7125],\n",
            "          device='cuda:0', dtype=torch.float64, grad_fn=<AliasBackward0>)\n",
            "0.12428157286500163\n",
            "0.24833862006304175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shc/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/pypose/lietensor/lietensor.py:918: UserWarning: Tensor Shape Invalid by calling <slot wrapper '__getitem__' of 'torch._C._TensorBase' objects>, go to https://pypose.org/docs/main/generated/pypose.LieTensor\n",
            "  warnings.warn('Tensor Shape Invalid by calling {}, ' \\\n"
          ]
        }
      ],
      "source": [
        "X = X.to(device)\n",
        "\n",
        "print('initial X:\\n', X)\n",
        "print('optimization result:\\n', res)\n",
        "print(X[:3].norm().item())\n",
        "print(res[:3].norm().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2294, -0.8229,  0.5198,  0.0202],\n",
            "        [ 0.2496,  0.5659,  0.7858,  0.0986],\n",
            "        [-0.9408, -0.0505,  0.3352,  0.0730],\n",
            "        [ 0.0000,  0.0000,  0.0000,  1.0000]], device='cuda:0',\n",
            "       dtype=torch.float64) \n",
            " tensor([[ 0.9954,  0.0272, -0.0914, -0.1040],\n",
            "        [-0.0198,  0.9965,  0.0816,  0.0724],\n",
            "        [ 0.0933, -0.0795,  0.9925, -0.1354],\n",
            "        [ 0.0000,  0.0000,  0.0000,  1.0000]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(pp.matrix(X),'\\n', pp.matrix(pp.Inv(res))@ pp.matrix(X))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nAQY4EnHmFoX",
        "om0hsJi5S6Pl",
        "rHQaC9QHs5K5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch3d",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ce49f5ef5efef132947d6c894613f203ae812a6bb9ec04c63c99638f20d472f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
