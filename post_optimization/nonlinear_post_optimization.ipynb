{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQY4EnHmFoX"
      },
      "source": [
        "## 0. Install and Import Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAHR1LMJmP-h"
      },
      "source": [
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7a3gdImMZx",
        "outputId": "59a23be5-a181-4789-e92f-defa24475895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.22.4)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (8.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=2a5a735959b1ed1a5c444b3f0a8b8c4fc0d7f2c5ffc6c6c47b9fce8c6fd6784d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=201007029374099283742884f8d86469d1265b3240302b52f894036335fd8d5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl (72.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (8.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.5.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import sys\n",
        "# import torch\n",
        "# need_pytorch3d=False\n",
        "# try:\n",
        "#     import pytorch3d\n",
        "# except ModuleNotFoundError:\n",
        "#     need_pytorch3d=True\n",
        "# if need_pytorch3d:\n",
        "#     if torch.__version__.startswith(\"1.13.\") and sys.platform.startswith(\"linux\"):\n",
        "#         # We try to install PyTorch3D via a released wheel.\n",
        "#         pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "#         version_str=\"\".join([\n",
        "#             f\"py3{sys.version_info.minor}_cu\",\n",
        "#             torch.version.cuda.replace(\".\",\"\"),\n",
        "#             f\"_pyt{pyt_version_str}\"\n",
        "#         ])\n",
        "#         !pip install fvcore iopath\n",
        "#         !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "#     else:\n",
        "#         # We try to install PyTorch3D from source.\n",
        "#         !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "#         !tar xzf 1.10.0.tar.gz\n",
        "#         os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "#         !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgLa7XQimFoY"
      },
      "outputs": [],
      "source": [
        "# # imports\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from pytorch3d.transforms.so3 import (\n",
        "#     so3_exp_map,\n",
        "#     so3_relative_angle,\n",
        "# )\n",
        "# from pytorch3d.transforms.se3 import (\n",
        "#     se3_exp_map,\n",
        "#     se3_log_map,\n",
        "# )\n",
        "\n",
        "# import pytorch3d.transforms as transforms\n",
        "    \n",
        "# # add path for demo utils\n",
        "# import sys\n",
        "# import os\n",
        "# sys.path.append(os.path.abspath(''))\n",
        "\n",
        "# # set for reproducibility\n",
        "# torch.manual_seed(42)\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda:0\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJHXNjKglfN"
      },
      "source": [
        "## **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_-eCm8alLqz"
      },
      "outputs": [],
      "source": [
        "# # Load the matrices \n",
        "# T_o_cb_batch = np.load('')\n",
        "# batch_size = T_o_cb_batch.shape[0]\n",
        "# T_o_p_batch = np.load('')\n",
        "# T_c_p_batch = np.load('')\n",
        "# X_matrix = np.load('')\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "\n",
        "# # Load into torch tensor\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbh1fFj-yOs4",
        "outputId": "ba72a33c-5d29-429e-c6b7-8b69fb57a246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.49508795 -0.8619929  -0.10888599  2.        ]\n",
            " [-0.86414445  0.47551297  0.16474763  2.        ]\n",
            " [-0.09023459  0.17565779 -0.98030712  2.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# ## test\n",
        "# from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# batch_size = 10\n",
        "# T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "# X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "# X_batch[:, :3, 3] = 2\n",
        "# print(X_batch[1, :,:])\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vy3GDAbgpxj"
      },
      "outputs": [],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # cam_gt: the ground truth camera pose w.r.t the optical tracker cam_gt = T_o_p * (T_c_p)^-1\n",
        "# cam_gt = T_o_cb.compose(X)\n",
        "\n",
        "# # cam_real: the camera pose from initial hand-eye calibration cam_real = T_o_cb * X\n",
        "# cam_real = T_o_p.compose(T_c_p.inverse())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om0hsJi5S6Pl"
      },
      "source": [
        "## **Define optimization loss function**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDA0vbgRSsD8"
      },
      "outputs": [],
      "source": [
        "# def camera_distance(hand_eye_real, hand_eye_gt):\n",
        "#   '''\n",
        "#   Calculate the l2 distance in se(3) manifold for the camera.\n",
        "#   distance = sum||log(hand_eye_real*hand_eye_gt)||_2\n",
        "#   '''\n",
        "\n",
        "#   # Convert a batch of 4x4 transformation matrices transform to \n",
        "#   # a batch of 6-dimensional SE(3) logarithms of the SE(3) matrices\n",
        "#   # print(hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix())\n",
        "#   tmp_matrix = hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix()\n",
        "#   vec = se3_log_map(tmp_matrix.permute(0,2,1)).sum(0)\n",
        "#   # print(torch.norm(vec))\n",
        "\n",
        "#   return torch.norm(vec)\n",
        "  \n",
        "\n",
        "# # camera_distance(cam_real, cam_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHQaC9QHs5K5"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STvOIf2IxfG6",
        "outputId": "0a326309-aa65-40f3-8168-a2e9df4c1655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration=  0; camera_distance=4.696e+01\n",
            "iteration=200; camera_distance=2.786e+01\n",
            "iteration=400; camera_distance=7.859e+00\n",
            "iteration=600; camera_distance=5.260e-04\n",
            "iteration=800; camera_distance=1.630e-02\n",
            "iteration=1000; camera_distance=7.543e-03\n",
            "iteration=1200; camera_distance=1.241e-02\n",
            "iteration=1400; camera_distance=7.818e-03\n",
            "iteration=1600; camera_distance=1.311e-02\n",
            "iteration=1800; camera_distance=3.938e-03\n",
            "iteration=1999; camera_distance=4.000e-03\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "# hand_eye_real_6D = se3_log_map(X.get_matrix().permute(0, 2, 1))\n",
        "# hand_eye_real_6D.requires_grad = True\n",
        "\n",
        "\n",
        "# # hand_eye_gt: the hand-eye transformation from the chain \n",
        "# # hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "# hand_eye_gt = T_o_cb.inverse().compose(T_o_p).compose(T_c_p.inverse())\n",
        "\n",
        "# # init the optimizer\n",
        "# optimizer = torch.optim.SGD([hand_eye_real_6D], lr=.001, momentum=0.9)\n",
        "\n",
        "# # run the optimization\n",
        "# n_iter = 2000  # fix the number of iterations\n",
        "# for it in range(n_iter):\n",
        "#     # re-init the optimizer gradients\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # transform the 6d vector into 4x4 matrix\n",
        "#     hand_eye_real = se3_exp_map(hand_eye_real_6D).permute(0, 2, 1)\n",
        "#     hand_eye_real = transforms.Transform3d(matrix=hand_eye_real, device=device)\n",
        "\n",
        "#     # compare the composed cameras with the ground truth relative cameras\n",
        "#     # camera_distance corresponds to $d$ from the description\n",
        "#     loss = \\\n",
        "#         camera_distance(hand_eye_real, hand_eye_gt)\n",
        "#     # loss.requires_grad_(True)\n",
        "\n",
        "#     # our loss function is the camera_distance\n",
        "#     loss.backward()\n",
        "    \n",
        "#     # apply the gradients\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # # plot and print status message\n",
        "#     if it % 200==0 or it==n_iter-1:\n",
        "#         status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "#         print(status)\n",
        "        \n",
        "# print('Optimization finished.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0Yz1ZM_bVG"
      },
      "source": [
        "## **Pypose implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHwar1t7_vlQ",
        "outputId": "94728a50-1b0a-4b15-d4f4-b95fb82b0e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypose\n",
            "  Downloading pypose-0.3.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.* in /usr/local/lib/python3.8/dist-packages (from pypose) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pypose) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.*->pypose) (4.5.0)\n",
            "Installing collected packages: pypose\n",
            "Successfully installed pypose-0.3.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install pypose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XHwVk3I7AJWz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shc/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch, pypose as pp\n",
        "from torch import nn\n",
        "from scipy.spatial.transform import Rotation as R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "efn4AgnkTlB3"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSkG7iFI2TAE"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoZzXm_s2Hhi"
      },
      "outputs": [],
      "source": [
        "# # Load the matrices \n",
        "# T_o_cb_batch = np.load('')\n",
        "# batch_size = T_o_cb_batch.shape[0]\n",
        "# T_o_p_batch = np.load('')\n",
        "# T_c_p_batch = np.load('')\n",
        "# X_matrix = np.load('')\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "\n",
        "# convert to pp tensor\n",
        "# X = pp.mat2SE3(X_batch)\n",
        "# T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "# T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "# T_c_p = pp.mat2SE3(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33skIGPvAgcG",
        "outputId": "549c1692-ecde-4aee-bea1-5dcefe9b6b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.61301403 -0.2401426   0.75269205  2.5       ]\n",
            " [ 0.7726237  -0.01690138 -0.63463924  2.5       ]\n",
            " [ 0.16512545  0.97059048  0.17517908  2.5       ]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "batch_size = 800\n",
        "T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "X_batch[:, :3, 3] = 2.5\n",
        "\n",
        "print(X_batch[1, :,:])\n",
        "\n",
        "# convert to pp tensor\n",
        "X = pp.mat2SE3(X_batch)\n",
        "T_o_p = pp.mat2SE3(T_o_p_batch)\n",
        "T_o_cb = pp.mat2SE3(T_o_cb_batch)\n",
        "T_c_p = pp.mat2SE3(T_c_p_batch)\n",
        "# print(X_batch[1,...])\n",
        "# print(X_batch @ pp.Inv(X_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3m2c_51-ON"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9GqcVTBSY-Sy"
      },
      "outputs": [],
      "source": [
        "class CamDis(nn.Module):\n",
        "    def __init__(self, hand_eye_real_6D):\n",
        "        super().__init__()\n",
        "        self.real = pp.Parameter(hand_eye_real_6D)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input hand_eye_gt\n",
        "        hand_eye_real = self.real.Exp()\n",
        "        tmp_quats = hand_eye_real @ pp.Inv(input)\n",
        "        vec = tmp_quats.Log()\n",
        "        # print(hand_eye_gt[0])\n",
        "        t = tmp_quats[:, :3].mean(0)\n",
        "        rot_vec = vec[:, 3:].mean(0)\n",
        "        return torch.norm(rot_vec) + torch.norm(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJomeMEsVpw5",
        "outputId": "27b5ee7c-9336-48fa-ef72-316e35185c2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shc/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/pypose/lietensor/lietensor.py:918: UserWarning: Tensor Shape Invalid by calling <slot wrapper '__getitem__' of 'torch._C._TensorBase' objects>, go to https://pypose.org/docs/main/generated/pypose.LieTensor\n",
            "  warnings.warn('Tensor Shape Invalid by calling {}, ' \\\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration=  0; camera_distance=1.467e+01\n",
            "iteration=  5; camera_distance=7.036e-02\n",
            "iteration= 10; camera_distance=6.477e-03\n",
            "iteration= 15; camera_distance=8.748e-04\n",
            "iteration= 20; camera_distance=1.183e-04\n",
            "iteration= 25; camera_distance=1.569e-05\n",
            "iteration= 30; camera_distance=9.219e-07\n",
            "Early Stopping with loss: 9.219348534101693e-07\n",
            "tensor([[ 1.0000e+00, -3.5636e-04, -1.2756e-04,  2.5622e-04],\n",
            "        [ 3.5640e-04,  1.0000e+00,  3.4686e-04,  2.6208e-04],\n",
            "        [ 1.2743e-04, -3.4690e-04,  1.0000e+00,  2.5407e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0',\n",
            "       dtype=torch.float64) SE3Type LieTensor:\n",
            "LieTensor([0., 0., 0., 0., 0., 0., 1.], device='cuda:0', dtype=torch.float64)\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "hand_eye_real = X\n",
        "hand_eye_real_6D = hand_eye_real.Log().to(device)\n",
        "\n",
        "# hand_eye_gt: the hand-eye transformation from the chain \n",
        "# hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "hand_eye_gt = pp.Inv(T_o_cb) @ T_o_p @ pp.Inv(T_c_p)\n",
        "\n",
        "# init the optimizer\n",
        "camera_distance = CamDis(hand_eye_real_6D).to(device)\n",
        "input = hand_eye_gt.to(device)\n",
        "strategy = pp.optim.strategy.Adaptive(damping=1e-6)\n",
        "optimizer = pp.optim.LM(camera_distance, strategy=strategy)\n",
        "\n",
        "# run the optimization\n",
        "n_iter = 200  # fix the number of iterations\n",
        "for it in range(n_iter):\n",
        "    loss = optimizer.step(input)\n",
        "\n",
        "    # # plot and print status message\n",
        "    if it % 5==0 or it==n_iter-1:\n",
        "        status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "        print(status)\n",
        "    if loss < 1e-6:\n",
        "        print('Early Stopping with loss:', loss.item())\n",
        "        break\n",
        "print(pp.matrix(hand_eye_real_6D[0].Exp()), input[0])\n",
        "print('Optimization finished.')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nAQY4EnHmFoX",
        "om0hsJi5S6Pl",
        "rHQaC9QHs5K5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch3d",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ce49f5ef5efef132947d6c894613f203ae812a6bb9ec04c63c99638f20d472f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
