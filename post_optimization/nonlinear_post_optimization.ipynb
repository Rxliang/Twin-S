{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQY4EnHmFoX"
      },
      "source": [
        "## 0. Install and Import Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAHR1LMJmP-h"
      },
      "source": [
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "uo7a3gdImMZx"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import sys\n",
        "# import torch\n",
        "# need_pytorch3d=False\n",
        "# try:\n",
        "#     import pytorch3d\n",
        "# except ModuleNotFoundError:\n",
        "#     need_pytorch3d=True\n",
        "# if need_pytorch3d:\n",
        "#     if torch.__version__.startswith(\"1.13.\") and sys.platform.startswith(\"linux\"):\n",
        "#         # We try to install PyTorch3D via a released wheel.\n",
        "#         pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "#         version_str=\"\".join([\n",
        "#             f\"py3{sys.version_info.minor}_cu\",\n",
        "#             torch.version.cuda.replace(\".\",\"\"),\n",
        "#             f\"_pyt{pyt_version_str}\"\n",
        "#         ])\n",
        "#         !pip install fvcore iopath\n",
        "#         !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "#     else:\n",
        "#         # We try to install PyTorch3D from source.\n",
        "#         !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "#         !tar xzf 1.10.0.tar.gz\n",
        "#         os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "#         !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgLa7XQimFoY",
        "outputId": "a3982f88-3cd7-49e6-d230-ce7e47ec63f5"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorch3d.transforms.so3 import (\n",
        "    so3_exp_map,\n",
        "    so3_relative_angle,\n",
        ")\n",
        "from pytorch3d.transforms.se3 import (\n",
        "    se3_exp_map,\n",
        "    se3_log_map,\n",
        ")\n",
        "\n",
        "import pytorch3d.transforms as transforms\n",
        "    \n",
        "# add path for demo utils\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(''))\n",
        "\n",
        "# set for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPhg0OXLzwID",
        "outputId": "691d55ce-9124-4f48-f062-a0480863231c"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/princeton-vl/lietorch.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJHXNjKglfN"
      },
      "source": [
        "## **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "p_-eCm8alLqz"
      },
      "outputs": [],
      "source": [
        "# # Load the matrices \n",
        "# T_o_cb_batch = np.load('')\n",
        "# batch_size = T_o_cb_batch.shape[0]\n",
        "# T_o_p_batch = np.load('')\n",
        "# T_c_p_batch = np.load('')\n",
        "# X_matrix = np.load('')\n",
        "# X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "\n",
        "# # Load into torch tensor\n",
        "# X_batch = torch.tensor(X_batch)\n",
        "# T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "# T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "# T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbh1fFj-yOs4",
        "outputId": "70c14033-d168-4ffe-ca24-880be4a94713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.48132905  0.86368179 -0.14958645  2.        ]\n",
            " [ 0.81857838  0.38188053 -0.42906491  2.        ]\n",
            " [-0.31345139 -0.32896964 -0.89080144  2.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "## test\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "batch_size = 800\n",
        "T_o_cb_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "T_o_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "T_c_p_batch = np.tile(np.eye(4), [batch_size,1,1])\n",
        "X_matrix = np.hstack((np.vstack((R.random().as_matrix(), np.zeros([1,3]))), np.ones([4,1])))\n",
        "X_batch = np.tile(X_matrix, [batch_size,1,1])\n",
        "X_batch[:, :3, 3] = 2\n",
        "print(X_batch[1, :,:])\n",
        "X_batch = torch.tensor(X_batch)\n",
        "T_o_p_batch = torch.tensor(T_o_p_batch)\n",
        "T_o_cb_batch = torch.tensor(T_o_cb_batch)\n",
        "T_c_p_batch = torch.tensor(T_c_p_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1vy3GDAbgpxj"
      },
      "outputs": [],
      "source": [
        "# # Create Transform3d objects from the batch of transformation matrices\n",
        "# T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "# X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "# T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "# T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# # cam_gt: the ground truth camera pose w.r.t the optical tracker cam_gt = T_o_p * (T_c_p)^-1\n",
        "# cam_gt = T_o_cb.compose(X)\n",
        "\n",
        "# # cam_real: the camera pose from initial hand-eye calibration cam_real = T_o_cb * X\n",
        "# cam_real = T_o_p.compose(T_c_p.inverse())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om0hsJi5S6Pl"
      },
      "source": [
        "## **Define optimization loss function**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "pDA0vbgRSsD8"
      },
      "outputs": [],
      "source": [
        "def camera_distance(hand_eye_real, hand_eye_gt):\n",
        "  '''\n",
        "  Calculate the l2 distance in se(3) manifold for the camera.\n",
        "  distance = sum||log(hand_eye_real*hand_eye_gt)||_2\n",
        "  '''\n",
        "\n",
        "  # Convert a batch of 4x4 transformation matrices transform to \n",
        "  # a batch of 6-dimensional SE(3) logarithms of the SE(3) matrices\n",
        "  # print(hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix())\n",
        "  tmp_matrix = hand_eye_real.compose(hand_eye_gt.inverse()).get_matrix()\n",
        "  vec = se3_log_map(tmp_matrix.permute(0,2,1)).sum(0)\n",
        "\n",
        "\n",
        "  return torch.norm(vec)\n",
        "  \n",
        "\n",
        "# camera_distance(cam_real, cam_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHQaC9QHs5K5"
      },
      "source": [
        "## **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "STvOIf2IxfG6",
        "outputId": "c2a74ca7-ca47-4c8c-9950-3f02b3a04c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration=  0; camera_distance=4.425e+03\n",
            "iteration=200; camera_distance=3.967e+03\n",
            "iteration=400; camera_distance=3.487e+03\n",
            "iteration=600; camera_distance=3.007e+03\n",
            "iteration=800; camera_distance=2.527e+03\n",
            "iteration=1000; camera_distance=2.047e+03\n",
            "iteration=1200; camera_distance=1.567e+03\n",
            "iteration=1400; camera_distance=1.087e+03\n",
            "iteration=1600; camera_distance=6.070e+02\n",
            "iteration=1800; camera_distance=1.270e+02\n",
            "iteration=2000; camera_distance=2.958e-01\n",
            "iteration=2200; camera_distance=3.692e-01\n",
            "iteration=2400; camera_distance=5.379e-01\n",
            "iteration=2600; camera_distance=1.320e-01\n",
            "iteration=2800; camera_distance=1.322e-01\n",
            "iteration=3000; camera_distance=1.322e-01\n",
            "iteration=3200; camera_distance=1.322e-01\n",
            "iteration=3400; camera_distance=1.322e-01\n",
            "iteration=3600; camera_distance=1.322e-01\n",
            "iteration=3800; camera_distance=1.322e-01\n",
            "iteration=3999; camera_distance=1.455e-01\n",
            "Optimization finished.\n"
          ]
        }
      ],
      "source": [
        "# Create Transform3d objects from the batch of transformation matrices\n",
        "T_o_cb = transforms.Transform3d(matrix=T_o_cb_batch, device=device)\n",
        "X = transforms.Transform3d(matrix=X_batch, device=device)\n",
        "T_o_p = transforms.Transform3d(matrix=T_o_p_batch, device=device)\n",
        "T_c_p = transforms.Transform3d(matrix=T_c_p_batch, device=device)\n",
        "\n",
        "# hand_eye_real: the hand-eye transformation from initial calibration X\n",
        "hand_eye_real_6D = se3_log_map(X.get_matrix().permute(0, 2, 1))\n",
        "hand_eye_real_6D.requires_grad = True\n",
        "\n",
        "\n",
        "# hand_eye_gt: the hand-eye transformation from the chain \n",
        "# hand_eye_gt = (T_o_cb)^-1 * T_o_p * (T_c_p)^-1\n",
        "hand_eye_gt = T_o_cb.inverse().compose(T_o_p).compose(T_c_p.inverse())\n",
        "\n",
        "# init the optimizer\n",
        "optimizer = torch.optim.SGD([hand_eye_real_6D], lr=.0003, momentum=0.9)\n",
        "\n",
        "# run the optimization\n",
        "n_iter = 4000  # fix the number of iterations\n",
        "for it in range(n_iter):\n",
        "    # re-init the optimizer gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # transform the 6d vector into 4x4 matrix\n",
        "    hand_eye_real = se3_exp_map(hand_eye_real_6D).permute(0, 2, 1)\n",
        "    hand_eye_real = transforms.Transform3d(matrix=hand_eye_real, device=device)\n",
        "\n",
        "    # compare the composed cameras with the ground truth relative cameras\n",
        "    # camera_distance corresponds to $d$ from the description\n",
        "    loss = \\\n",
        "        camera_distance(hand_eye_real, hand_eye_gt)\n",
        "    # loss.requires_grad_(True)\n",
        "\n",
        "    # our loss function is the camera_distance\n",
        "    loss.backward()\n",
        "    \n",
        "    # apply the gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # # plot and print status message\n",
        "    if it % 200==0 or it==n_iter-1:\n",
        "        status = 'iteration=%3d; camera_distance=%1.3e' % (it, loss)\n",
        "        print(status)\n",
        "print('Optimization finished.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch3d",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ce49f5ef5efef132947d6c894613f203ae812a6bb9ec04c63c99638f20d472f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
