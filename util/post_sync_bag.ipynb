{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import rosbag\n",
    "import rospy\n",
    "import ros_numpy\n",
    "import bagpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "from ros_tools import rostools\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "sys.path.insert(0, '../optical_tracking')\n",
    "from phantom_registration import manual_registration, draw_registration_result\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "sys.path.insert(0, '../util')\n",
    "from Solver import solver\n",
    "sol = solver()\n",
    "rt = rostools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_geometry_msgs__PoseStamped' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m l_img_topic \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/sync_limage/compressed\u001b[39m\u001b[39m'\u001b[39m \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m initialization()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m main()\n",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 2\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     \u001b[39m# bag2csv(bag_file)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     \u001b[39m# bag2Pointcloud(bag_file, pcd_topic)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     \u001b[39m# bag2zedPointcloud(bag_file, zed_pcd_topic)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     bag2image(bag_file, l_img_topic)\n",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 2\u001b[0m in \u001b[0;36mbag2image\u001b[0;34m(bag_file, l_img_topic)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m# sec_list.append('1')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mwith\u001b[39;00m rosbag\u001b[39m.\u001b[39mBag(bag_file, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m bag:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W1sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     rt\u001b[39m.\u001b[39;49msaveImagesFromBag(bag, sec_list, l_img_topic, limg_path)\n",
      "File \u001b[0;32m~/Twin-S/util/ros_tools.py:219\u001b[0m, in \u001b[0;36mrostools.saveImagesFromBag\u001b[0;34m(self, bag, topics, img_sec_list, path)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m# img_sec_list.append(img_sec)\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     cv_image \u001b[39m=\u001b[39m bridge\u001b[39m.\u001b[39;49mcompressed_imgmsg_to_cv2(msg, desired_encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpassthrough\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m CvBridgeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    221\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "File \u001b[0;32m/opt/ros/noetic/lib/python3/dist-packages/cv_bridge/core.py:124\u001b[0m, in \u001b[0;36mCvBridge.compressed_imgmsg_to_cv2\u001b[0;34m(self, cmprs_img_msg, desired_encoding)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m str_msg \u001b[39m=\u001b[39m cmprs_img_msg\u001b[39m.\u001b[39;49mdata\n\u001b[1;32m    125\u001b[0m buf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(str_msg)),\n\u001b[1;32m    126\u001b[0m                   dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8, buffer\u001b[39m=\u001b[39mcmprs_img_msg\u001b[39m.\u001b[39mdata)\n\u001b[1;32m    127\u001b[0m im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimdecode(buf, cv2\u001b[39m.\u001b[39mIMREAD_UNCHANGED)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_geometry_msgs__PoseStamped' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "\n",
    "def initialization():\n",
    "    global file, depth_path, zed_path, limg_path, output_dir\n",
    "\n",
    "    output_dir = bag_file[:-4]\n",
    "\n",
    "    valid = rt.verify_cv_bridge()\n",
    "    # verify_ROS_connection()\n",
    "    limg_path = output_dir +'/limg/'\n",
    "    depth_path = output_dir +'/depth_pcd/'\n",
    "    zed_path = output_dir +'/zed_depth_pcd/'\n",
    "\n",
    "    if not os.path.exists(depth_path):\n",
    "        os.makedirs(depth_path)\n",
    "        print(\"Create Folder at Designated Address depth_path...\")\n",
    "    if not os.path.exists(zed_path):\n",
    "        os.makedirs(zed_path)\n",
    "        print(\"Create Folder at Designated Address depth_path...\")\n",
    "    if not os.path.exists(limg_path):\n",
    "        os.makedirs(limg_path)\n",
    "        print(\"Create Folder at Designated Address limg...\")\n",
    "\n",
    "def bag2csv(bag_file):\n",
    "    b = bagpy.bagreader(bag_file)\n",
    "    b.message_by_topic('/sync_pose_pan')\n",
    "    b.message_by_topic('/sync_pose_camhand')\n",
    "    print(\"Complete Saving csv.\")\n",
    "\n",
    "\n",
    "# def bag2pcd(bag_file, pcd_topic):\n",
    "#     bridge = CvBridge()\n",
    "#     start = time.time()\n",
    "    \n",
    "#     with rosbag.Bag(bag_file, 'r') as bag:\n",
    "#         for topic, depth_msg, t in bag.read_messages(pcd_topic):\n",
    "#             pcd = rt.rospc_to_o3dpc(depth_msg)\n",
    "#             save_dir = os.path.join(depth_path, f'{t}.ply')\n",
    "#             open3d.io.write_point_cloud(save_dir, pcd)\n",
    "#             end = time.time()\n",
    "#             print(end - start)\n",
    "#             print(\"Complete Saving\")\n",
    "\n",
    "def bag2Pointcloud(bag_file, pcd_topic):\n",
    "    conversion = 0.180\n",
    "    depth_threshold = 0.5\n",
    "    with rosbag.Bag(bag_file, 'r') as bag:\n",
    "        count = 0\n",
    "        start = time.time()\n",
    "        for topic, depth_msg, t in bag.read_messages(pcd_topic):\n",
    "            pcd = rt.rospc_to_o3dpc(depth_msg)\n",
    "            R_ros2cv = np.array([[0,1,0],[0,0,-1],[-1,0,0]])  \n",
    "            # R_ros2cv = np.identity(3)        \n",
    "            pcd.points = o3d.utility.Vector3dVector((R_ros2cv@(np.asarray(pcd.points)*conversion).transpose(-1,-2)).transpose(-1,-2))\n",
    "\n",
    "            # Filter out\n",
    "            np_pcd= np.asarray(pcd.points)\n",
    "            distances = np.sqrt(np.sum(np_pcd**2, axis=1))\n",
    "            threshold = np.min(distances) + depth_threshold\n",
    "            filtered_point_cloud = np_pcd[distances <= 1]\n",
    "            # filtered_point_cloud = np_pcd[np.logical_and(distances <=1, distances > 0.01)]\n",
    "            pcd.points = o3d.utility.Vector3dVector(filtered_point_cloud)\n",
    "            # o3d.visualization.draw_geometries_with_editing([pcd])\n",
    "            save_dir = os.path.join(depth_path, str(count)) + '.ply'\n",
    "            o3d.io.write_point_cloud(save_dir, pcd)\n",
    "            count += 1\n",
    "            \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        print(\"Complete Saving\")\n",
    "\n",
    "def bag2zedPointcloud(bag_file, zed_pcd_topic):\n",
    "\n",
    "    with rosbag.Bag(bag_file, 'r') as bag:\n",
    "        count = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        count = 0\n",
    "        for topic, depth_msg, t in bag.read_messages(zed_pcd_topic):\n",
    "            zed_pcd = rt.rospc_to_o3dpc(depth_msg)\n",
    "            \n",
    "            R_zed2cv = np.array([[0,-1,0],[0,0,-1],[1,0,0]])\n",
    "            \n",
    "            # pcd = o3d.geometry.PointCloud()\n",
    "            zed_pcd.points = o3d.utility.Vector3dVector((R_zed2cv@np.asarray(zed_pcd.points).transpose(-1,-2)).transpose(-1,-2))\n",
    "\n",
    "            save_dir = os.path.join(zed_path, str(count)) + '.ply'\n",
    "            o3d.io.write_point_cloud(save_dir, zed_pcd)\n",
    "            count += 1\n",
    "            \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        print(\"Complete Saving\")\n",
    "\n",
    "def bag2image(bag_file, l_img_topic):\n",
    "    sec_list=[]\n",
    "    # sec_list.append('1')\n",
    "    with rosbag.Bag(bag_file, 'r') as bag:\n",
    "        rt.saveImagesFromBag(bag, sec_list, l_img_topic, limg_path)\n",
    "\n",
    "def main():\n",
    "    bag2csv(bag_file)\n",
    "    bag2Pointcloud(bag_file, pcd_topic)\n",
    "    bag2zedPointcloud(bag_file, zed_pcd_topic)\n",
    "    # bag2image(bag_file, l_img_topic)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rt = rostools()\n",
    "    bridge = CvBridge()\n",
    "    global args, bag_file\n",
    "    bag_file = '/media/shc/Elements/Twin-S_data/post_sync/post_sync_z.bag'\n",
    "    pcd_topic = '/sync_pcd/DepthData'\n",
    "    zed_pcd_topic = '/sync_zedpcd/DepthData'\n",
    "    l_img_topic = '/sync_limage/compressed' \n",
    "    initialization()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopen3d\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mo3d\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pcd_source \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_point_cloud(\u001b[39m'\u001b[39m\u001b[39m/media/shc/Elements/Twin-S_data/post_sync/post_sync_eval1/depth_pcd/280.ply\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m o3d\u001b[39m.\u001b[39;49mvisualization\u001b[39m.\u001b[39;49mdraw_geometries_with_editing([pcd_source])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "pcd_source = o3d.io.read_point_cloud('/media/shc/Elements/Twin-S_data/post_sync/post_sync_eval1/depth_pcd/280.ply')\n",
    "o3d.visualization.draw_geometries_with_editing([pcd_source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPly: Unable to open file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: unable to open file: /media/shc/Elements/Twin-S_data/post_sync/post_sync/cropped_1.ply\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "            size=0.1, origin=[0, 0, 0])\n",
    "pcd_source = o3d.io.read_point_cloud('/media/shc/Elements/Twin-S_data/post_sync/post_sync/cropped_1.ply')\n",
    "pcd_source = o3d.io.read_point_cloud('/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/zed_depth_pcd/0.ply')\n",
    "# pcd_target = o3d.io.read_point_cloud('/media/shc/Elements/Twin-S_data/post_sync/post_sync/depth_pcd/0.ply')\n",
    "# o3d.visualization.draw_geometries_with_editing([pcd_target])\n",
    "o3d.visualization.draw_geometries([pcd_source, mesh_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization of two point clouds before manual alignment\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #2204 (0.051, 0.027, 0.28) to add in queue.\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] Picked point #4578 (0.026, 0.013, 0.28) to add in queue.\n",
      "[Open3D INFO] Picked point #303 (0.037, 0.045, 0.29) to add in queue.\n",
      "\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #10116 (0.0062, 0.013, 0.00098) to add in queue.\n",
      "[Open3D INFO] Picked point #10136 (-0.02, 0.0029, 0.0038) to add in queue.\n",
      "[Open3D INFO] Picked point #36432 (0.0064, 0.0080, 0.025) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by user\n",
      "Perform point-to-point ICP refinement\n",
      "\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.956629e-04, and correspondence_set size of 12562\n",
      "Access transformation to get result.\n",
      "[[ 0.80323514  0.46893193  0.36730935 -0.15135272]\n",
      " [ 0.14936826  0.43837205 -0.88629514  0.2430845 ]\n",
      " [-0.57663024  0.76676776  0.28207229 -0.07089025]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def phantom_registration(pcd_source, T_c_p_path=None):\n",
    "\n",
    "    pcd_target = o3d.io.read_point_cloud(\"../data/phantom_point-cloud_data/phacon_exp_3.ply\")\n",
    "    pcd_target = pcd_target.voxel_down_sample(voxel_size=0.001)\n",
    "\n",
    "    # manual registration to initialize\n",
    "    init_result = manual_registration(pcd_source, pcd_target)\n",
    "\n",
    "    threshold = 0.006\n",
    "    loss = o3d.pipelines.registration.TukeyLoss(k=0.005)\n",
    "\n",
    "    trans_init_icp = init_result.transformation\n",
    "\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_source, pcd_target, threshold, trans_init_icp,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(loss))\n",
    "        \n",
    "    draw_registration_result(pcd_source, pcd_target, result.transformation)\n",
    "    print(result)\n",
    "    print(result.transformation)\n",
    "    return result.transformation\n",
    "\n",
    "idx = '90'\n",
    "pcd_source = o3d.io.read_point_cloud(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/depth_pcd/cropped_{idx}.ply')\n",
    "T_p_ac = phantom_registration(pcd_source)\n",
    "np.save(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/T_p_ac_{idx}_a.npy', T_p_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealPose(idx, pd_data):\n",
    "    df = pd_data\n",
    "    pose_x = df['pose.position.x'][idx]*1000\n",
    "    pose_y = df['pose.position.y'][idx]*1000\n",
    "    pose_z = df['pose.position.z'][idx]*1000\n",
    "    orin_x = df['pose.orientation.x'][idx]\n",
    "    orin_y = df['pose.orientation.y'][idx]\n",
    "    orin_z = df['pose.orientation.z'][idx]\n",
    "    orin_w = df['pose.orientation.w'][idx]\n",
    "    pose = np.array([pose_x, pose_y, pose_z, orin_x, orin_y, orin_z, orin_w])\n",
    "    # print(real_pose, '\\n', pose)\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '0411'\n",
    "opti_dir = f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z'\n",
    "params_save_dir = opti_dir\n",
    "T_cb_c =  np.load(f'../params/hand_eye_X_optimized_{date}.npy')\n",
    "T_p_pb = np.load(f'../params/phacon2pan_{date}.npy')\n",
    "T_pb_p = sol.invTransformation(T_p_pb)\n",
    "\n",
    "\n",
    "pose_pan_data = os.path.join(opti_dir, 'sync_pose_pan.csv')\n",
    "pose_cam_data = os.path.join(opti_dir, 'sync_pose_camhand.csv')\n",
    "\n",
    "df_pan = pd.read_csv(pose_pan_data)\n",
    "df_cam_hand = pd.read_csv(pose_cam_data)\n",
    "\n",
    "# assert len(df_pan == df_cam_hand)\n",
    "num_frames = len(df_pan)\n",
    "T_c_p_batch = np.zeros([num_frames, 4, 4])\n",
    "for i in range(num_frames):\n",
    "    quaternion_pb = getRealPose(i, df_pan)\n",
    "    quaternion_cb = getRealPose(i, df_cam_hand)\n",
    "    _, T_o_pb = sol.seven2trans(quaternion_pb)\n",
    "    _, T_o_cb = sol.seven2trans(quaternion_cb)\n",
    "    # T_o_p_batch[i, :, :] = T_o_pb @ T_pb_p\n",
    "    # T_o_cb_batch[i,:,:] = T_o_cb\n",
    "    T_o_c = T_o_cb@T_cb_c\n",
    "    # offset \n",
    "    T_c_corr = np.identity(4)\n",
    "    T_c_corr[0,3] = 8.3\n",
    "    T_c_corr[1,3] = 5.6 \n",
    "    T_o_c = np.dot(T_o_c, T_c_corr)\n",
    "\n",
    "    T_o_p = T_o_pb @ T_pb_p\n",
    "    T_c_p_real = sol.invTransformation(T_o_c)@T_o_p\n",
    "    T_c_p_batch[i,:,:] = T_c_p_real\n",
    "    \n",
    "    np.save(os.path.join(params_save_dir, f'T_c_p_real_offset.npy'),T_c_p_batch)\n",
    "    # print(T_c_p_real[:3, 3])\n",
    "    # break\n",
    "# np.save(os.path.join(params_save_dir, f'T_o_p_opti{opti_num}_0321.npy'), T_o_p_batch)\n",
    "# np.save(os.path.join(params_save_dir, f'T_o_cb_opti{opti_num}_0321.npy'), T_o_cb_batch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ZED, AMBF, and CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# draw_registration_result(pcd_target, pcd_zed, T_c_p)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m pcd_target\u001b[39m.\u001b[39mtransform(T_c_p[count])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m o3d\u001b[39m.\u001b[39;49mvisualization\u001b[39m.\u001b[39;49mdraw_geometries([pcd_target, pcd_zed, pcd_ambf], front\u001b[39m=\u001b[39;49m[ \u001b[39m-\u001b[39;49m\u001b[39m0.3509939981295529\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.0013414501852417977\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.93637674778287405\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     lookat\u001b[39m=\u001b[39;49m[ \u001b[39m-\u001b[39;49m\u001b[39m0.0044998621935288937\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.029191735052132683\u001b[39;49m, \u001b[39m0.34626969113492007\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     up\u001b[39m=\u001b[39;49m[ \u001b[39m0.90668866085024358\u001b[39;49m, \u001b[39m0.24932730419749116\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.34022282061496678\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     zoom\u001b[39m=\u001b[39;49m\u001b[39m0.38000000000000006\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m pcd_target\u001b[39m.\u001b[39mtransform(sol\u001b[39m.\u001b[39minvTransformation(T_c_p[count]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "date = '0411'\n",
    "opti_dir = f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z'\n",
    "T_c_p = np.load(os.path.join(opti_dir, f'T_c_p_real_offset.npy'))\n",
    "zed_pcd_dir = os.path.join(opti_dir, 'zed_depth_pcd')\n",
    "ambf_pcd_dir = os.path.join(opti_dir, 'depth_pcd')\n",
    "T_c_p[...,:3 ,3] /= 1000\n",
    "pcd_target = o3d.io.read_point_cloud(\"../data/phantom_point-cloud_data/phacon_exp_3.ply\")\n",
    "\n",
    "zed_pointclouds = natsorted([os.path.join(zed_pcd_dir, f) for f in os.listdir(zed_pcd_dir) if \".ply\" in f])\n",
    "ambf_pointclouds = natsorted([os.path.join(ambf_pcd_dir, f) for f in os.listdir(ambf_pcd_dir) if \".ply\" in f])\n",
    "\n",
    "# visulize result\n",
    "for [count,pointcloud] in enumerate(zip(zed_pointclouds, ambf_pointclouds)):\n",
    "    pcd_zed = o3d.io.read_point_cloud(os.path.join(zed_pcd_dir, pointcloud[0]))\n",
    "    pcd_ambf = o3d.io.read_point_cloud(os.path.join(ambf_pcd_dir, pointcloud[1]))\n",
    "    pcd_ambf.paint_uniform_color([1, 0.706, 1])\n",
    "    # draw_registration_result(pcd_target, pcd_zed, T_c_p)\n",
    "    \n",
    "    pcd_target.transform(T_c_p[count])\n",
    "    o3d.visualization.draw_geometries([pcd_target, pcd_zed, pcd_ambf], front=[ -0.3509939981295529, -0.0013414501852417977, -0.93637674778287405 ],\n",
    "        lookat=[ -0.0044998621935288937, -0.029191735052132683, 0.34626969113492007 ],\n",
    "        up=[ 0.90668866085024358, 0.24932730419749116, -0.34022282061496678 ],\n",
    "        zoom=0.38000000000000006)\n",
    "    pcd_target.transform(sol.invTransformation(T_c_p[count]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ZED and CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m pcd_ambf\u001b[39m.\u001b[39mpaint_uniform_color([\u001b[39m1\u001b[39m, \u001b[39m0.706\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pcd_target\u001b[39m.\u001b[39mtransform(T_c_p[count])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m o3d\u001b[39m.\u001b[39;49mvisualization\u001b[39m.\u001b[39;49mdraw_geometries([pcd_target, pcd_ambf], front\u001b[39m=\u001b[39;49m[ \u001b[39m-\u001b[39;49m\u001b[39m0.14054829969218396\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.21430914598217043\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.96660114080319037\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     lookat\u001b[39m=\u001b[39;49m[ \u001b[39m-\u001b[39;49m\u001b[39m0.064506968418826249\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.017665959520745674\u001b[39;49m, \u001b[39m0.34775550426918295\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     up\u001b[39m=\u001b[39;49m[ \u001b[39m0.95587178555563934\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.28376383648487885\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.076073745024526532\u001b[39;49m ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     zoom\u001b[39m=\u001b[39;49m\u001b[39m0.46\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m pcd_target\u001b[39m.\u001b[39mtransform(sol\u001b[39m.\u001b[39minvTransformation(T_c_p[count]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# date = '0411'\n",
    "opti_dir = f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_eval2'\n",
    "T_c_p = np.load(os.path.join(opti_dir, f'T_c_p_real.npy'))\n",
    "ambf_pcd_dir = os.path.join(opti_dir, 'depth_pcd')\n",
    "T_c_p[...,:3 ,3] /= 1000\n",
    "pcd_target = o3d.io.read_point_cloud(\"../data/phantom_point-cloud_data/phacon_exp_3.ply\")\n",
    "\n",
    "ambf_pointclouds = natsorted([os.path.join(ambf_pcd_dir, f) for f in os.listdir(ambf_pcd_dir) if \".ply\" in f])\n",
    "\n",
    "# visulize result\n",
    "for [count,pointcloud] in enumerate(ambf_pointclouds):\n",
    "    pcd_ambf = o3d.io.read_point_cloud(os.path.join(ambf_pcd_dir, pointcloud))\n",
    "    pcd_ambf.paint_uniform_color([1, 0.706, 1])\n",
    "    \n",
    "    pcd_target.transform(T_c_p[count])\n",
    "    o3d.visualization.draw_geometries([pcd_target, pcd_ambf], front=[ -0.14054829969218396, -0.21430914598217043, -0.96660114080319037 ],\n",
    "        lookat=[ -0.064506968418826249, -0.017665959520745674, 0.34775550426918295 ],\n",
    "        up=[ 0.95587178555563934, -0.28376383648487885, -0.076073745024526532 ],\n",
    "        zoom=0.46)\n",
    "    pcd_target.transform(sol.invTransformation(T_c_p[count]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval overlay of pointcloud and RGB of ZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "def project_pointcloud_to_image(pointcloud, intrinsics, extrinsics, image_shape):\n",
    "    # Convert point cloud from 3D coordinates to 2D image coordinates\n",
    "    points_2d, _ = cv2.projectPoints(pointcloud, extrinsics[:3], extrinsics[3:], intrinsics, distCoeffs=None)\n",
    "    # Scale the 2D points to the size of the image\n",
    "    points_2d = np.squeeze(points_2d)\n",
    "    points_2d[:, 0] = np.clip(points_2d[:, 0], 0, image_shape[1] - 1)\n",
    "    points_2d[:, 1] = np.clip(points_2d[:, 1], 0, image_shape[0] - 1)\n",
    "    points_2d = np.round(points_2d).astype(int)\n",
    "\n",
    "    # Create an empty image\n",
    "    image = np.zeros((image_shape[0], image_shape[1], 3), dtype=np.uint8)\n",
    "    dists = np.linalg.norm(pointcloud[:, :3], axis=1)  # compute distances from point to camera\n",
    "\n",
    "    # # Assign RGB colors to the projected points\n",
    "    cmap_norm = mpl.colors.Normalize(vmin=np.min(dists), vmax=np.max(dists))\n",
    "    pixs_colors = plt.get_cmap('jet')(cmap_norm(dists))[:, 0:3]*255\n",
    "    for i, point in enumerate(points_2d):\n",
    "        c_ = tuple(pixs_colors[i].astype(np.uint8))\n",
    "        c_ = np.uint8(c_)\n",
    "        x, y = point\n",
    "        r, g, b = int(c_[0]),int(c_[1]),int(c_[2])\n",
    "        image[y, x] = [r, g, b]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85628, 3)\n",
      "(92322, 3)\n",
      "(88464, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m zed_pcd \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(zed_pcd\u001b[39m.\u001b[39mpoints)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(zed_pcd\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m pcd_img \u001b[39m=\u001b[39m project_pointcloud_to_image(zed_pcd, intrinsics, extrinsics, image_shape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m left_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/limg/\u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m.jpeg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39maddWeighted(left_img, \u001b[39m0.5\u001b[39m, pcd_img, \u001b[39m0.9\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m/home/shc/Twin-S/util/post_sync_bag.ipynb Cell 14\u001b[0m in \u001b[0;36mproject_pointcloud_to_image\u001b[0;34m(pointcloud, intrinsics, extrinsics, image_shape)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m pixs_colors \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mget_cmap(\u001b[39m'\u001b[39m\u001b[39mjet\u001b[39m\u001b[39m'\u001b[39m)(cmap_norm(dists))[:, \u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, point \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(points_2d):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     c_ \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(pixs_colors[i]\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     c_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8(c_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shc/Twin-S/util/post_sync_bag.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x, y \u001b[39m=\u001b[39m point\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opti_dir = f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z'\n",
    "zed_pcd_dir = os.path.join(opti_dir, 'zed_depth_pcd')\n",
    "intrinsics = np.load('../params/zed_M_l.npy')\n",
    "extrinsics = np.zeros([6,1])\n",
    "image_shape = (1080, 1920)\n",
    "zed_pointclouds = natsorted([os.path.join(zed_pcd_dir, f) for f in os.listdir(zed_pcd_dir) if \".ply\" in f])\n",
    "\n",
    "output_file = cv2.VideoWriter(\n",
    "            filename='/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/zed_overlay.mp4',\n",
    "            fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps=15,\n",
    "            frameSize=(1920, 1080),\n",
    "            isColor=True,\n",
    "        )\n",
    "\n",
    "for [count,zed_pointcloud] in enumerate(zed_pointclouds):\n",
    "    zed_pcd = o3d.io.read_point_cloud(zed_pointcloud)\n",
    "    zed_pcd = np.asarray(zed_pcd.points)\n",
    "    print(zed_pcd.shape)\n",
    "    pcd_img = project_pointcloud_to_image(zed_pcd, intrinsics, extrinsics, image_shape)\n",
    "\n",
    "    left_img = cv2.imread(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/limg/{count}.jpeg')\n",
    "    img = cv2.addWeighted(left_img, 0.5, pcd_img, 0.9, 0)\n",
    "    # cv2.imwrite(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/zed_overlay/{count}.jpeg', img)\n",
    "    output_file.write(img)\n",
    "    # if count == 50:\n",
    "    #     break\n",
    "output_file.release()\n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ambf overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44665466e+03 0.00000000e+00 3.20000000e+02]\n",
      " [0.00000000e+00 1.44665466e+03 1.80000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "opti_dir = f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z'\n",
    "ambf_pcd_dir = os.path.join(opti_dir, 'depth_pcd')\n",
    "intrinsics = np.load('../params/zed_M_l.npy')\n",
    "intrinsics[0, 2] = 960\n",
    "intrinsics[1, 2] = 540\n",
    "print(intrinsics)\n",
    "\n",
    "extrinsics = np.zeros([6,1])\n",
    "\n",
    "image_shape = (1080, 1920)\n",
    "ambf_pointclouds = natsorted([os.path.join(ambf_pcd_dir, f) for f in os.listdir(ambf_pcd_dir) if \".ply\" in f])\n",
    "\n",
    "output_file = cv2.VideoWriter(\n",
    "            filename='/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/ambf_overlay_.mp4',\n",
    "            fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps=15,\n",
    "            frameSize=(1920, 1080),\n",
    "            isColor=True,\n",
    "        )\n",
    "\n",
    "for [count,ambf_pointcloud] in enumerate(ambf_pointclouds):\n",
    "    ambf_pcd = o3d.io.read_point_cloud(ambf_pointcloud)\n",
    "    ambf_pcd = np.asarray(ambf_pcd.points)\n",
    "    pcd_img = project_pointcloud_to_image(ambf_pcd, intrinsics, extrinsics, image_shape)\n",
    "    sim_img = cv2.imread(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/sim_img/{count}.jpeg')\n",
    "    sim_img = cv2.resize(sim_img, (1920, 1080))\n",
    "    left_img = cv2.imread(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/limg/{count}.jpeg')\n",
    "    img = cv2.addWeighted(sim_img, 0.5, pcd_img, 0.9, 0)\n",
    "    # cv2.imwrite(f'/media/shc/Elements/Twin-S_data/post_sync/post_sync_z/zed_overlay/{count}.jpeg', img)\n",
    "    output_file.write(img)\n",
    "    # if count == 50:\n",
    "    #     break\n",
    "output_file.release()\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
